{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "781a36c9",
   "metadata": {},
   "source": [
    "This repo is based on DiffScaler, https://github.com/DSIP-FBK/DiffScaler/tree/main/src"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f60f02f",
   "metadata": {},
   "source": [
    "You are already acquainted with Pytorch now as a fanstastic library for writing, modifying, testing and scaling up the code. In this notebook, let us learn a cool wrapper library for Pytorch known as Pytorch Lightning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9556bf29",
   "metadata": {},
   "source": [
    "A great resource to learn about the differences between Pytorch and Pytorch Lightning and how Pytorch Lightning makes your life easier : https://www.geeksforgeeks.org/deep-learning/pytorch-vs-pytorch-lightning/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00ee6fee",
   "metadata": {},
   "source": [
    "Please note that according to this TA, you can`t really appreciate the resurcefulness of Pytorch lightning without learning the basics of Pytorch. Hence, take this tutorial as a 10,000 ft overview of what Pytorch and Pytorch lightning actually do. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1041bed3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader, Dataset, random_split, TensorDataset\n",
    "import torch.nn.functional as F\n",
    "from lightning import LightningModule, LightningDataModule, Trainer\n",
    "from lightning.pytorch.callbacks import EarlyStopping, ModelCheckpoint\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from omegaconf import OmegaConf\n",
    "import hydra\n",
    "import random\n",
    "import zstandard\n",
    "import os\n",
    "import glob\n",
    "import io\n",
    "import xarray as xr\n",
    "import rasterio\n",
    "import rioxarray\n",
    "import json\n",
    "import yaml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "78b635d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from preprocessing import load_and_normalise, decompress_zst_pt, get_file_list, collate_fn"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "375d5e12",
   "metadata": {},
   "source": [
    "Training the hierarchy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e840f325",
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg=OmegaConf.load(\"conf/config_experiments.yaml\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5a389acd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from short_exercise import DownscalingDataModule"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8c3c9450",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using 48 samples from 2020.\n",
      "Using 48 samples from 2020.\n"
     ]
    }
   ],
   "source": [
    "data_module = DownscalingDataModule(\n",
    "    batch_size=1,\n",
    "    val_frac=cfg.data.val_split,\n",
    "    test_frac=cfg.data.test_split,\n",
    "    num_workers=cfg.data.num_workers,\n",
    "    static_dir=cfg.paths.static_dir,\n",
    "    save_stats_json=os.path.join(cfg.paths.output_dir, \"stats.json\")\n",
    ")\n",
    "data_module.setup()\n",
    "test_loader = data_module.test_dataloader()\n",
    "\n",
    "# Get a single test sample (input and ground truth)\n",
    "test_iter = iter(test_loader)\n",
    "input_sample, ground_truth = next(test_iter)\n",
    "input_sample = input_sample[0] \n",
    "ground_truth = ground_truth[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3785db5",
   "metadata": {},
   "source": [
    "Writing the YAML file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8af1d0ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "def inference(cfg, input_sample, ground_truth=None):\n",
    "    stats_path = os.path.join(cfg.paths.output_dir, \"stats.json\")\n",
    "    with open(stats_path, \"r\") as f:\n",
    "        stats = json.load(f)\n",
    "    low_2mt_mean = stats[\"low_2mt_mean\"]\n",
    "    low_2mt_std = stats[\"low_2mt_std\"]\n",
    "\n",
    "    def denormalise(arr):\n",
    "        return arr * low_2mt_std + low_2mt_mean\n",
    "\n",
    "    # Load ckpts for UNet, VAE, LDM\n",
    "    checkpoint_dir = cfg.paths.checkpoint_dir\n",
    "    unet_module = UNetLitModule.load_from_checkpoint(\n",
    "        os.path.join(checkpoint_dir, \"unet\", sorted(os.listdir(checkpoint_dir + \"/unet\"))[-1])\n",
    "    )\n",
    "    vae_module = VAELitModule.load_from_checkpoint(\n",
    "        os.path.join(checkpoint_dir, \"vae\", sorted(os.listdir(checkpoint_dir + \"/vae\"))[-1])\n",
    "    )\n",
    "    ldm_module = LDMLitModule.load_from_checkpoint(\n",
    "        os.path.join(checkpoint_dir, \"ldm\", sorted(os.listdir(checkpoint_dir + \"/ldm\"))[-1]),\n",
    "        vae=vae_module\n",
    "    )\n",
    "\n",
    "    unet_module.eval()\n",
    "    vae_module.eval()\n",
    "    ldm_module.eval()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        device = next(unet_module.parameters()).device\n",
    "        fuzzy_input = input_sample.unsqueeze(0).to(device)\n",
    "        unet_pred = unet_module.net(fuzzy_input)\n",
    "\n",
    "        input_height = vae_module.hparams.input_height // 2\n",
    "        input_width = vae_module.hparams.input_width // 2\n",
    "        latent_shape = (1, 1, input_height, input_width)\n",
    "\n",
    "        # Downsample unet_pred to latent spatial size\n",
    "        unet_pred_ds = F.interpolate(unet_pred, size=(input_height, input_width), mode='bilinear', align_corners=False)\n",
    "\n",
    "        # Generate 3 samples\n",
    "        generated_latents = []\n",
    "        for _ in range(3):\n",
    "            z_sample = ldm_module.sample(latent_shape, unet_pred_ds)\n",
    "            z_sample_flat = z_sample.view(z_sample.size(0), -1)\n",
    "            generated_latents.append(z_sample_flat)\n",
    "\n",
    "        generated_latents = torch.cat(generated_latents, dim=0)\n",
    "\n",
    "        # Decode latents to residuals\n",
    "        generated_residuals = vae_module.model.decode(generated_latents, unet_pred)\n",
    "\n",
    "        final_reconstructions = unet_pred + generated_residuals\n",
    "\n",
    "    # Prepare images for plotting\n",
    "    all_imgs = [\n",
    "        denormalise(fuzzy_input[0, 0].cpu().numpy()),  # ERA5 predictor\n",
    "        denormalise(final_reconstructions[0, 0].cpu().numpy()),  # Sample 1\n",
    "        denormalise(final_reconstructions[1, 0].cpu().numpy()),  # Sample 2\n",
    "        denormalise(final_reconstructions[2, 0].cpu().numpy()),  # Sample 3\n",
    "    ]\n",
    "    titles = [\n",
    "        \"ERA5 2m input\",\n",
    "        \"Sample 1\",\n",
    "        \"Sample 2\",\n",
    "        \"Sample 3\",\n",
    "    ]\n",
    "\n",
    "    # Add ground truth if provided\n",
    "    if ground_truth is not None:\n",
    "        all_imgs.append(denormalise(ground_truth.cpu().numpy()))\n",
    "        titles.append(\"Ground Truth\")\n",
    "\n",
    "    vmin = min(img.min() for img in all_imgs)\n",
    "    vmax = max(img.max() for img in all_imgs)\n",
    "\n",
    "    fig, axes = plt.subplots(1, len(all_imgs), figsize=(6 * len(all_imgs), 6), constrained_layout=True)\n",
    "    images = []\n",
    "\n",
    "    for i, ax in enumerate(axes):\n",
    "        im = ax.imshow(all_imgs[i], cmap='coolwarm', vmin=vmin, vmax=vmax, origin='lower')\n",
    "        ax.set_title(titles[i], fontsize=15, fontweight='bold')\n",
    "        ax.set_xlabel(\"Longitude\", fontsize=13)\n",
    "        ax.set_ylabel(\"Latitude\", fontsize=13)\n",
    "        ax.tick_params(axis='both', which='major', labelsize=11)\n",
    "        ax.grid(False, which='both')\n",
    "        images.append(im)\n",
    "\n",
    "    cbar = fig.colorbar(images[0], ax=axes, orientation='horizontal', fraction=0.04, pad=0.08)\n",
    "    cbar.set_label(\"2m Temperature (C)\", fontsize=15, fontweight='bold')\n",
    "    cbar.ax.tick_params(labelsize=13)\n",
    "\n",
    "    plt.suptitle(\"ERA5 low res + 3 samples + Ground Truth (conditional inference)\", fontsize=20, y=1.05, fontweight='bold')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "85d4f473",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'UNetLitModule' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m#Now that the models are trained,,, how will you perform inference using the trained hierarchy?\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m \u001b[43minference\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcfg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minput_sample\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mground_truth\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[6], line 13\u001b[0m, in \u001b[0;36minference\u001b[0;34m(cfg, input_sample, ground_truth)\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[38;5;66;03m# Load ckpts for UNet, VAE, LDM\u001b[39;00m\n\u001b[1;32m     12\u001b[0m checkpoint_dir \u001b[38;5;241m=\u001b[39m cfg\u001b[38;5;241m.\u001b[39mpaths\u001b[38;5;241m.\u001b[39mcheckpoint_dir\n\u001b[0;32m---> 13\u001b[0m unet_module \u001b[38;5;241m=\u001b[39m \u001b[43mUNetLitModule\u001b[49m\u001b[38;5;241m.\u001b[39mload_from_checkpoint(\n\u001b[1;32m     14\u001b[0m     os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(checkpoint_dir, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124munet\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28msorted\u001b[39m(os\u001b[38;5;241m.\u001b[39mlistdir(checkpoint_dir \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m/unet\u001b[39m\u001b[38;5;124m\"\u001b[39m))[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m])\n\u001b[1;32m     15\u001b[0m )\n\u001b[1;32m     16\u001b[0m vae_module \u001b[38;5;241m=\u001b[39m VAELitModule\u001b[38;5;241m.\u001b[39mload_from_checkpoint(\n\u001b[1;32m     17\u001b[0m     os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(checkpoint_dir, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvae\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28msorted\u001b[39m(os\u001b[38;5;241m.\u001b[39mlistdir(checkpoint_dir \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m/vae\u001b[39m\u001b[38;5;124m\"\u001b[39m))[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m])\n\u001b[1;32m     18\u001b[0m )\n\u001b[1;32m     19\u001b[0m ldm_module \u001b[38;5;241m=\u001b[39m LDMLitModule\u001b[38;5;241m.\u001b[39mload_from_checkpoint(\n\u001b[1;32m     20\u001b[0m     os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(checkpoint_dir, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mldm\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28msorted\u001b[39m(os\u001b[38;5;241m.\u001b[39mlistdir(checkpoint_dir \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m/ldm\u001b[39m\u001b[38;5;124m\"\u001b[39m))[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]),\n\u001b[1;32m     21\u001b[0m     vae\u001b[38;5;241m=\u001b[39mvae_module\n\u001b[1;32m     22\u001b[0m )\n",
      "\u001b[0;31mNameError\u001b[0m: name 'UNetLitModule' is not defined"
     ]
    }
   ],
   "source": [
    "#Now that the models are trained,,, how will you perform inference using the trained hierarchy?\n",
    "inference(cfg, input_sample, ground_truth)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "diffscaler",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.23"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
